\label{ch:conclusion}

In this chapter, we briefly describe existing verification approaches, how they differ from our Oracle-guided approach, and summarize the contributions in this thesis.
\section{Related Work}
\paragraph{Counterexample Guided Abstraction Refinement}
% CEGAR:
A broad class of verifiers of programs and transition systems have
been proposed that implement \emph{counterexample-example guided
  abstraction refinement (CEGAR)}~\cite{clarke03}.
%
The common structure of all of these analyses is that they maintain an
approximate model of the possible runs of a system, and refine the
model until it represents a proof of correctness by iteratively (1)
choosing a path of execution $p$ allowed by the model that, if
feasible, constitutes a property violation, (2) refuting the
feasibility of $p$, and (3) using the refutation to refine the paths
of execution allowed by the model.
% Relative Completeness of Abstraction Refinement for Software Model
% Checking: Oracle is really angelic non-determinism.
The CEGAR-based analysis that is most closely related to the
one proposed in this work is actually a \emph{theoretical} analysis
that chooses program facts from which to construct a refutation by
querying a \emph{widening Oracle}~\cite{ball02}.
%
The key property of the counterexample-guided analysis is that if there is
sequence of widenings that the Oracle can possible choose to cause the
analysis to verify a program, then the analysis will eventually verify
the program successfully.
%
Because the Oracle does not solve a distinct problem, but instead
provides values to the analysis, it can be viewed as an agent of
\emph{angelic non-determinism}~\cite{bodik10}.
% Us:
While \verifier also queries an Oracle, the Oracle solves a problem
distinct from providing values to the analysis, namely an active
learning problem over both positive \emph{and negative} example
heap graphs.

\paragraph{Predicate Abstraction}
% Predicate Abstraction:
Predicate abstraction is an abstract interpretation technique in which the abstract domain is constructed from a given set of predicates over program variables. The concrete states of a system are mapped to abstract states according to their evaluation under a finite set of predicates. Automatic predicate abstraction algorithms have been designed and implemented before for finite and for infinite state systems. Predicate abstraction is well established in the literature \cite{ball01,henzinger02,henzinger04}. The primary limitation with most of these techniques is that predicates in logic cannot describe shapes.
% Us:
\verifier uses predicates to annotate heap patterns, relying on other technique to infer these predicates beforehand. Predicate abstraction is useful to do that, although we need more investigation into how to use it to infer the right predicates for our technique in a directed way and efficiently.

\paragraph{Interpolation}
% Interpolation
Interpolants have been widely studied and used in model checking and software verification. In various contexts, interpolation can be used as a substitute for image computation, which involves quantifier elimination and is thus computationally expensive. The idea is to replace the image with a weaker approximation that is still strong enough to prove some property, helping to construct and inductive invariant. Interpolant based techniques typically examine symbolic executions (finite paths) through the program, explicitly enumerating paths and employing heuristics to avoid path explosion \cite{albarghouthi12,heizmann10,mcmillan06,rummer13}. Some of them use other optimizations to cover wider search spaces, or compute invariants more efficiently. \verifier also uses the notion of interpolants applied to sequences, but specifically for heap patterns. Existing techniques don't work for this case because they deal with formulas that cannot desribe heaps or shapes in memory.
% Us

\paragraph{Active Learning}
% Active learning
Active learning has explored as yet another technique, which is particularly useful for dealing with verification of data structures. The framework proposed in \cite{garg13} can model quantified invariants over linear data structures, and build poly-time active learning algorithms for them, where the learner is allowed to query the teacher with membership and equivalence queries.
% Madhu's paper: only works on bounded tuples of lists
% Us

\paragraph{Shape Analysis}
In program analysis, a shape analysis is a static code analysis technique that discovers and verifies properties of linked, dynamically allocated data structures in (usually imperative) computer programs. It has been applied to a variety of problems, including memory safety and checking state properties. For example, proving that two data structures cannot access the same piece of memory, or discriminating between cyclic and acyclic lists. Separation logic \cite{calcagano11,reynolds02} is one component of existing work on shape analysis. It extends the simple imperative programming language with commands (not expressions) for accessing and modifying shared structures, and for explicit allocation and deallocation of storage. Assertions are extended by introducing a ``separating conjunction'' that asserts that its subformulas hold for disjoint parts of the heap, and a closely related ``separating implication''. Coupled with the inductive definition of predicates on abstract data structures, this extension permits the concise and flexible description of
structures with controlled sharing. Separation logic is quite expressive, but the major challenge lies in finding a suitable decidable sub-logic that is expressive enough for a given domain.

In addition to the logic approach, memory graphs have been extensively explored for shape analysis. A parametric framework for shape analysis was presented in \cite{sagiv02}, which can be instantiated in different ways to create shape-analysis algorithms that provide varying degrees of efficiency and precision. It also proposed three-valued logic structures, an idea we extensively use to model heap patterns in our work. Symbolic Memory Graphs (SMGs) \cite{dudka13} are another effective approach, particularly for modeling extremely low-level operations. The heap patterns used in \verifier are partially inspired by SMGs, but work at a higher level that is more suitable for an external Oracle, and in an interpolation-based verification framework.
% Us

\paragraph{Crowdsourcing}
% Other examples of humans as oracles
Describe crowdsourcing in verification and other areas, like HCI.
% Madhu's paper: only works on bounded tuples of lists
% Us

\section{Summary}
Our work can be summarized using the following key ideas:

\begin{enumerate}
  \item We extended the interpolant-based verification algorithm from \cite{mcmillan06} to work for the domain of heap-manipulating programs.
  \item We defined the heap pattern formalism for expressing sets of concrete heaps.
  \item We introduced the idea of Oracle-guided verification, defining a framework which allows the verification algorithm to use an external Oracle for the generalization step.
  \item We demonstrated one example of such an Oracle - a human user who is inherently good at generalizing shapes, and can provide valuable insight to help find heap invariants.
\end{enumerate}

Our framework is very general, in the sense that it allows for any kind of ``pattern'' formalism to be used alongside a domain expert Oracle. This provides two advantages. Firstly, it makes it very easy to try a simple interpolation-based verification algorithm for a new domain, where one might not have good automated techniques for generalization, but good ``intuitive'' understanding about it. Secondly, it simplifies plugging in different Oracles into an existing verification algorithm, allowing for broader possible insight into the analysis. It is easy to extend this to the case of allowing for multiple Oracles working side by side in a single analysis, providing complementary insight into a verification problem. In the future, a theoretical analysis of Oracle-guided verification algorithms would be an interesting direction.

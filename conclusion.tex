\label{ch:conclusion}

In this chapter, we briefly describe existing verification approaches, how they differ from our Oracle-guided approach, and summarize the contributions in this thesis.
\section{Related Work}
\paragraph{Counterexample Guided Abstraction Refinement}
% CEGAR:
A broad class of verifiers of programs and transition systems have
been proposed that implement \emph{counterexample-example guided
  abstraction refinement (CEGAR)}~\cite{clarke03}.
%
The common structure of all of these analyses is that they maintain an
approximate model of the possible runs of a system, and refine the
model until it represents a proof of correctness by iteratively (1)
choosing a path of execution $p$ allowed by the model that, if
feasible, constitutes a property violation, (2) refuting the
feasibility of $p$, and (3) using the refutation to refine the paths
of execution allowed by the model.
% Relative Completeness of Abstraction Refinement for Software Model
% Checking: Oracle is really angelic non-determinism.
The CEGAR-based analysis that is most closely related to the
one proposed in this work is actually a \emph{theoretical} analysis
that chooses program facts from which to construct a refutation by
querying a \emph{widening Oracle}~\cite{ball02}.
%
The key property of the counterexample-guided analysis is that if there is
sequence of widenings that the Oracle can possible choose to cause the
analysis to verify a program, then the analysis will eventually verify
the program successfully.
%
Because the Oracle does not solve a distinct problem, but instead
provides values to the analysis, it can be viewed as an agent of
\emph{angelic non-determinism}~\cite{bodik10}.
% Us:
While \verifier also queries an Oracle, the Oracle solves a problem
distinct from providing values to the analysis, namely an active
learning problem over both positive \emph{and negative} example
heap graphs.

\paragraph{Predicate Abstraction}
% Predicate Abstraction:
Predicate abstraction is an abstract interpretation technique in which the abstract domain is constructed from a given set of predicates over program variables. The concrete states of a system are mapped to abstract states according to their evaluation under a finite set of predicates. Automatic predicate abstraction algorithms have been designed and implemented before for finite and for infinite state systems. Predicate abstraction is well established in the literature \cite{ball01,henzinger02,henzinger04}. The primary limitation with most of these techniques is that predicates in logic cannot describe shapes.
% Us:
\verifier uses predicates to annotate heap patterns, relying on other technique to infer these predicates beforehand. Predicate abstraction is useful to do that, although we need more investigation into how to use it to infer the right predicates for our technique in a directed way and efficiently.

\paragraph{Interpolation}
% Interpolation
Interpolants have been widely studied and used in model checking and software verification. In various contexts, interpolation can be used as a substitute for image computation, which involves quantifier elimination and is thus computationally expensive. The idea is to replace the image with a weaker approximation that is still strong enough to prove some property, helping to construct and inductive invariant. Interpolant based techniques typically examine symbolic executions (finite paths) through the program, explicitly enumerating paths and employing heuristics to avoid path explosion \cite{albarghouthi12,heizmann10,mcmillan06,rummer13}. Some of them use other optimizations to cover wider search spaces, or compute invariants more efficiently. \verifier also uses the notion of interpolants applied to sequences, but specifically for heap patterns. Existing techniques don't work for this case because they deal with formulas that cannot desribe heaps or shapes in memory.
% Us

\paragraph{Active Learning}
% Active learning
Active learning has explored as yet another technique, which is particularly useful for dealing with verification of data structures. The framework proposed in \cite{garg13} can model quantified invariants over linear data structures, and build poly-time active learning algorithms for them, where the learner is allowed to query the teacher with membership and equivalence queries.
% Madhu's paper: only works on bounded tuples of lists
% Us

\paragraph{Shape Analysis}

-memory graphs: TVLA~\cite{sagiv02}, SMG's\cite{dudka13}

-separation logic~\cite{calcagano11,reynolds02}
% Us
